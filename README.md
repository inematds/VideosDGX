# VideosDGX - Docker Multi-Container para Video LLMs

Infraestrutura containerizada para rodar modelos de geraÃ§Ã£o de vÃ­deo no DGX Spark 2026.

## ğŸ“‹ VisÃ£o Geral

Este projeto fornece uma arquitetura Docker multi-container para executar 4 modelos de geraÃ§Ã£o de vÃ­deo:

- **LTX-2**: GeraÃ§Ã£o completa de vÃ­deo + Ã¡udio (FP4, ~25-30GB)
- **Wan 2.1**: Modelo versÃ¡til de 14B parÃ¢metros (FP8, ~28-32GB)
- **MAGI-1**: Modelo autoregressive para vÃ­deos longos (FP4, ~20-25GB)
- **Waver 1.0**: Modelo leve para batch generation (FP8, ~15-18GB)

## ğŸ¯ Status Atual (2026-02-16)

### âœ… Funcionando

- âœ… **Docker Containers**: Todos os 4 containers (ltx2, wan21, magi1, waver) estÃ£o UP e respondendo
- âœ… **APIs REST**: Endpoints /health retornando status saudÃ¡vel em todas as portas (8001-8004)
- âœ… **Job Submission**: Jobs de geraÃ§Ã£o de vÃ­deo aceitos com sucesso por todos os modelos
- âœ… **Modelos Baixados**:
  - LTX-2: 293GB completo (checkpoint 41GB + Gemma FP8 6GB + projections 2.7GB + audio VAE 208MB)
  - Wan 2.1: 65GB completo (modelo montado de 6 shards)
  - MAGI-1: Download em andamento
  - Waver: DisponÃ­vel no Docker volume

### âš ï¸ Issues Conhecidos

1. **LTX-2**: Carregamento iniciou mas travou em 50% (4/8 shards) - possÃ­vel timeout ou OOM
2. **Wan 2.1 & Waver**: Erro `torch.xpu` AttributeError durante inicializaÃ§Ã£o (relacionado a ARM64 + CUDA)
3. **MAGI-1**: Erro de configuraÃ§Ã£o - falta `model_type` no config.json
4. **CUDA Memory**: Sistema host com 117GB/120GB VRAM jÃ¡ alocados, impedindo testes locais

### ğŸ“ Scripts de Teste DisponÃ­veis

- `generate_all_videos.py`: Submete jobs de geraÃ§Ã£o para todos os 4 modelos simultaneamente
- `check_jobs_status.py`: Monitora status dos jobs em loop (10s de intervalo, 10min timeout)
- `test_ltx2_direct.py`: Testa LTX-2 via API Python direta (ltx_pipelines)
- `test_ltx2_cpu.py`: Teste de fallback em CPU (extremamente lento)

### CaracterÃ­sticas

- âœ… Isolamento por container (controle granular)
- âœ… APIs REST completas para cada modelo
- âœ… Carregamento sob demanda (lazy loading)
- âœ… QuantizaÃ§Ã£o otimizada (FP4/FP8)
- âœ… Gerenciamento de fila de jobs
- âœ… Health checks e mÃ©tricas
- âœ… Volumes persistentes para modelos e outputs

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DGX Spark 2026                       â”‚
â”‚              128GB Unified Memory + Blackwell           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LTX-2      â”‚  Wan 2.1    â”‚  MAGI-1     â”‚  Waver 1.0   â”‚
â”‚  :8001      â”‚  :8002      â”‚  :8003      â”‚  :8004       â”‚
â”‚  FP4        â”‚  FP8        â”‚  FP4        â”‚  FP8         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚              â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                   â”‚   Volumes   â”‚
                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                   â”‚   models/   â”‚
                   â”‚   outputs/  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### PrÃ©-requisitos

- Docker Engine 24.0+
- Docker Compose 2.20+
- NVIDIA Docker Runtime
- GPU com suporte CUDA 12.3+
- ~100GB de espaÃ§o em disco (para modelos)

### 1. Build da Base Image

Primeiro, construa a imagem base compartilhada:

```bash
docker build -t videosdgx-base:latest -f common/base.Dockerfile .
```

### 2. Download dos Modelos

Execute o script de download (interativo):

```bash
./scripts/download_models.sh
```

Ou baixe manualmente usando HuggingFace CLI:

```bash
# Criar volume
docker volume create videosdgx_models

# Exemplo: baixar LTX-2
huggingface-cli download Lightricks/LTX-Video --local-dir /var/lib/docker/volumes/videosdgx_models/_data/ltx2
```

### 3. Build dos Containers

```bash
docker-compose build
```

### 4. Iniciar os ServiÃ§os

```bash
docker-compose up -d
```

### 5. Verificar Status

```bash
./scripts/health_check.py
```

SaÃ­da esperada:

```
=========================================
VideosDGX - Health Check
=========================================

â— LTX-2
   Status:      Online
   Endpoint:    http://localhost:8001
   Modelo:      NÃ£o carregado
   GPU Memory:  0.5GB / 128GB
   CPU Memory:  0.8GB / 128GB
   Queue:       0 jobs

...
```

## ğŸ“¡ Uso das APIs

Todas as APIs seguem o mesmo padrÃ£o REST.

### Endpoints DisponÃ­veis

| Endpoint | MÃ©todo | DescriÃ§Ã£o |
|----------|--------|-----------|
| `/` | GET | InformaÃ§Ãµes gerais da API |
| `/health` | GET | Health check bÃ¡sico |
| `/ready` | GET | Verifica se modelo estÃ¡ carregado |
| `/info` | GET | InformaÃ§Ãµes detalhadas (sistema + modelo) |
| `/generate` | POST | Gera vÃ­deo a partir de prompt |
| `/unload` | POST | Descarrega modelo da memÃ³ria |
| `/queue/status` | GET | Status da fila de jobs |
| `/jobs/{job_id}` | GET | Status de um job especÃ­fico |
| `/jobs/{job_id}/download` | GET | Download do vÃ­deo gerado |
| `/metrics` | GET | MÃ©tricas de performance |

### Exemplo: Gerar VÃ­deo

```bash
# LTX-2 (porta 8001)
curl -X POST http://localhost:8001/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "A cat walking on a beach at sunset",
    "duration": 5,
    "resolution": "1024x576",
    "fps": 24,
    "seed": 42,
    "guidance_scale": 7.5
  }'
```

Resposta:

```json
{
  "job_id": "ltx2-abc12345",
  "status": "queued",
  "queue_position": 1,
  "estimated_time_seconds": 60,
  "model_loaded": false
}
```

### Verificar Status do Job

```bash
curl http://localhost:8001/jobs/ltx2-abc12345
```

Resposta (em processamento):

```json
{
  "job_id": "ltx2-abc12345",
  "model_name": "ltx2",
  "status": "processing",
  "prompt": "A cat walking on a beach at sunset",
  "duration": 5,
  "created_at": "2026-02-15T10:30:00",
  "started_at": "2026-02-15T10:30:05",
  "completed_at": null,
  "output_path": null,
  "error": null,
  "progress": 45
}
```

### Download do VÃ­deo

```bash
# Quando status = "completed"
curl -O http://localhost:8001/jobs/ltx2-abc12345/download
```

Ou acesse diretamente no navegador: `http://localhost:8001/jobs/ltx2-abc12345/download`

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente (.env)

```bash
# Auto-unload: minutos de inatividade antes de descarregar modelo
# 0 = nunca descarregar
AUTO_UNLOAD_MINUTES=30

# Logging
LOG_LEVEL=INFO
```

### Portas dos ServiÃ§os

| Modelo | Porta | Endpoint |
|--------|-------|----------|
| LTX-2 | 8001 | http://localhost:8001 |
| Wan 2.1 | 8002 | http://localhost:8002 |
| MAGI-1 | 8003 | http://localhost:8003 |
| Waver 1.0 | 8004 | http://localhost:8004 |

## ğŸ“Š Monitoramento

### Health Check

```bash
./scripts/health_check.py
```

### Benchmark

Testar performance de todos os modelos:

```bash
./scripts/benchmark.py
```

Testar apenas um modelo:

```bash
./scripts/benchmark.py --model ltx2
```

Teste rÃ¡pido:

```bash
./scripts/benchmark.py --quick
```

### Logs dos Containers

```bash
# Todos os containers
docker-compose logs -f

# Container especÃ­fico
docker-compose logs -f ltx2

# Ãšltimas 100 linhas
docker-compose logs --tail=100 wan21
```

### Uso de Recursos

```bash
# GPU
nvidia-smi

# Containers
docker stats

# Volumes
docker volume inspect videosdgx_models
docker volume inspect videosdgx_outputs
```

## ğŸ¯ Gerenciamento de MemÃ³ria

### EstratÃ©gia de Carregamento

1. **Container inicia**: API pronta, modelo NÃƒO carregado (~500MB RAM)
2. **Primeira requisiÃ§Ã£o**: Modelo carregado automaticamente
3. **RequisiÃ§Ãµes subsequentes**: Modelo jÃ¡ em memÃ³ria (rÃ¡pido)
4. **Auto-unload**: ApÃ³s X minutos de inatividade (configurÃ¡vel)

### Estimativa de MemÃ³ria

Com 128GB de memÃ³ria unificada:

| Modelo | QuantizaÃ§Ã£o | MemÃ³ria | Tempo de Carga |
|--------|-------------|---------|----------------|
| LTX-2 | FP4 | ~25-30GB | ~60-90s |
| Wan 2.1 | FP8 | ~28-32GB | ~70-100s |
| MAGI-1 | FP4 | ~20-25GB | ~50-80s |
| Waver 1.0 | FP8 | ~15-18GB | ~40-60s |

**Capacidade**: 3-4 modelos carregados simultaneamente

### Descarregar Modelo Manualmente

```bash
curl -X POST http://localhost:8001/unload
```

Resposta:

```json
{
  "status": "unloaded",
  "model_name": "ltx2",
  "memory_freed_gb": 28.5,
  "memory_after": {
    "allocated_gb": 0.5,
    "free_gb": 127.5
  }
}
```

## ğŸ”„ Abordagens Alternativas

AlÃ©m da arquitetura Docker, este projeto inclui duas abordagens alternativas configuradas:

### ComfyUI (Recomendado pela NVIDIA)

ComfyUI estÃ¡ instalado e configurado com custom nodes para LTX-2:

```bash
# Ativar ambiente
source comfyui-env/bin/activate

# Iniciar servidor (requer resolver issue de memÃ³ria)
cd ComfyUI
python main.py --port 8188

# Acessar: http://localhost:8188
```

**LocalizaÃ§Ã£o dos modelos ComfyUI**:
- Checkpoint: `ComfyUI/models/checkpoints/ltx-2-19b-distilled.safetensors` (41GB)
- Text Encoder: `ComfyUI/models/clip/gemma_3_12B_it_fp8_e4m3fn.safetensors` (6GB)
- Projections: `ComfyUI/models/clip/ltx-2-19b-dev-fp4_projections_only.safetensors` (2.7GB)
- Audio VAE: `ComfyUI/models/vae/LTX2_audio_vae_bf16.safetensors` (208MB)

**Custom Nodes**:
- ComfyUI-LTXVideo (oficial Lightricks)
- MAGI-1 (SandAI-org)

### Python API Direta (LTX-2)

API oficial da Lightricks instalada via pip:

```bash
# Ativar ambiente
source comfyui-env/bin/activate

# Gerar vÃ­deo via linha de comando
python -m ltx_pipelines.distilled \
  --checkpoint-path ComfyUI/models/checkpoints/ltx-2-19b-distilled.safetensors \
  --gemma-root ComfyUI/models/clip/ \
  --prompt "A cat walking on a beach at sunset" \
  --output-path output.mp4 \
  --num-frames 65 \
  --height 512 \
  --width 768 \
  --num-inference-steps 8 \
  --guidance-scale 3.0
```

**Pacotes instalados**:
- `ltx-core`
- `ltx-pipelines`

## ğŸ§ª Testes Realizados

### GeraÃ§Ã£o de VÃ­deos (16/02/2026)

Executado `generate_all_videos.py` com prompt: *"A cat walking on a beach at sunset, cinematic camera movement, golden hour lighting, 4k quality"*

**Resultados**:

| Modelo | Status | Job ID | Detalhes |
|--------|--------|--------|----------|
| LTX-2 | â¸ï¸ Travado | ltx2-26252c62 | Carregamento iniciou (50%), depois timeout |
| Wan 2.1 | âŒ Falhou | wan21-66eb1181 | torch.xpu AttributeError |
| MAGI-1 | âŒ Falhou | magi1-5d8c2647 | Config.json sem model_type |
| Waver | âŒ Falhou | waver-cf98097a | torch.xpu AttributeError |

**Log completo**: `generation_results.log`

## ğŸ› ï¸ Comandos Ãšteis

### Docker Compose

```bash
# Iniciar todos os serviÃ§os
docker-compose up -d

# Parar todos os serviÃ§os
docker-compose down

# Rebuild de um serviÃ§o especÃ­fico
docker-compose build ltx2

# Restart de um serviÃ§o
docker-compose restart wan21

# Ver logs
docker-compose logs -f

# Escalar serviÃ§o (nÃ£o recomendado para GPUs)
docker-compose up -d --scale waver=2
```

### Volumes

```bash
# Listar volumes
docker volume ls

# Inspecionar volume
docker volume inspect videosdgx_models

# Backup de modelos
docker run --rm -v videosdgx_models:/data -v $(pwd):/backup \
  ubuntu tar czf /backup/models_backup.tar.gz /data

# Restore de modelos
docker run --rm -v videosdgx_models:/data -v $(pwd):/backup \
  ubuntu tar xzf /backup/models_backup.tar.gz -C /data
```

### Limpeza

```bash
# Parar e remover containers
docker-compose down

# Remover volumes (CUIDADO: apaga modelos!)
docker-compose down -v

# Limpar imagens nÃ£o utilizadas
docker image prune -a

# Limpar tudo (CUIDADO!)
docker system prune -a --volumes
```

## ğŸ› Troubleshooting

### Container nÃ£o inicia

```bash
# Verificar logs
docker-compose logs ltx2

# Verificar GPU
nvidia-smi

# Verificar NVIDIA runtime
docker run --rm --gpus all nvidia/cuda:12.3.0-base-ubuntu22.04 nvidia-smi
```

### Modelo nÃ£o carrega

```bash
# Verificar se modelo existe
docker volume inspect videosdgx_models

# Verificar permissÃµes
docker exec videosdgx-ltx2 ls -la /models/ltx2

# Verificar logs de carregamento
docker-compose logs ltx2 | grep "Carregando"
```

### Out of Memory

```bash
# Verificar memÃ³ria GPU
nvidia-smi

# Descarregar modelos nÃ£o usados
curl -X POST http://localhost:8001/unload
curl -X POST http://localhost:8002/unload

# Reiniciar container
docker-compose restart ltx2
```

### Performance lenta

1. Verificar se modelo estÃ¡ carregado: `curl http://localhost:8001/ready`
2. Verificar fila: `curl http://localhost:8001/queue/status`
3. Verificar mÃ©tricas: `curl http://localhost:8001/metrics`
4. Ajustar nÃºmero de inference steps nas configs

### âš ï¸ Erros Conhecidos e SoluÃ§Ãµes

#### 1. torch.xpu AttributeError (Wan 2.1, Waver)

**Erro**:
```
AttributeError: module 'torch' has no attribute 'xpu'
```

**Causa**: Bibliotecas tentando detectar Intel XPU em ambiente ARM64 + CUDA

**SoluÃ§Ãµes tentadas**:
- âŒ Environment variables (`ACCELERATE_USE_XPU=0`)
- âŒ Monkey-patching `torch.xpu`
- â³ **SoluÃ§Ã£o necessÃ¡ria**: Patch no cÃ³digo de inicializaÃ§Ã£o dos containers

**Workaround temporÃ¡rio**:
```python
# Adicionar antes de imports de diffusers/accelerate
import torch
if not hasattr(torch, 'xpu'):
    class DummyXPU:
        @staticmethod
        def is_available(): return False
    torch.xpu = DummyXPU()
```

#### 2. CUDA Out of Memory (Sistema Host)

**Erro**:
```
RuntimeError: CUDA out of memory. Tried to allocate X GB
(GPU 0; 120.00 GiB total capacity; 117.00 GiB already allocated)
```

**Causa**: Processo root (PID 2351379) consumindo 117GB/120GB VRAM

**SoluÃ§Ã£o**:
```bash
# Requer sudo
sudo kill -9 2351379
sudo sh -c 'sync; echo 3 > /proc/sys/vm/drop_caches'
nvidia-smi
```

**VerificaÃ§Ã£o**:
```bash
# Mostrar processos usando GPU
fuser -v /dev/nvidia*
ps aux | grep 2351379
```

#### 3. MAGI-1 Config Missing

**Erro**:
```
Unrecognized model in /models/magi1. Should have a `model_type` key in its config.json
```

**Causa**: Download incompleto ou configuraÃ§Ã£o ausente

**SoluÃ§Ã£o**:
```bash
# Verificar integridade do download
docker exec videosdgx-magi1 ls -lah /models/magi1/
docker exec videosdgx-magi1 cat /models/magi1/config.json

# Re-download se necessÃ¡rio
docker exec videosdgx-magi1 huggingface-cli download SandAI-org/MAGI-1 --local-dir /models/magi1
```

#### 4. LTX-2 Loading Timeout

**Sintoma**: Carregamento trava em 50% (4/8 checkpoint shards)

**DiagnÃ³stico**:
```bash
# Verificar logs detalhados
docker logs videosdgx-ltx2 --tail 200

# Verificar uso de memÃ³ria durante carregamento
docker stats videosdgx-ltx2

# Verificar se processo estÃ¡ travado ou apenas lento
docker exec videosdgx-ltx2 ps aux
```

**PossÃ­veis causas**:
- OOM durante carregamento de shards grandes
- Deadlock em carregamento multi-threaded
- Timeout muito curto nas requisiÃ§Ãµes

**SoluÃ§Ã£o**:
```bash
# Aumentar timeout no check_jobs_status.py
max_iterations = 120  # 20 minutos ao invÃ©s de 10

# Ou restart do container
docker-compose restart ltx2
```

#### 5. Gemma Model Gated (resolvido)

**Erro**: `403 Client Error: Forbidden for url: google/gemma-3-12b-it`

**SoluÃ§Ã£o aplicada**: Usar modelo alternativo nÃ£o-gated
```bash
# Baixado: GitMylo/LTX-2-comfy_gemma_fp8_e4m3fn
# LocalizaÃ§Ã£o: ComfyUI/models/clip/gemma_3_12B_it_fp8_e4m3fn.safetensors
```

## ğŸ“š Estrutura de Arquivos

```
VideosDGX/
â”œâ”€â”€ common/                    # CÃ³digo compartilhado (Docker)
â”‚   â”œâ”€â”€ base.Dockerfile        # Base image com CUDA + PyTorch
â”‚   â”œâ”€â”€ api_base.py            # Framework FastAPI
â”‚   â”œâ”€â”€ model_loader.py        # Gerenciador de modelos
â”‚   â””â”€â”€ utils.py               # Utilidades (logging, metrics)
â”œâ”€â”€ ltx2/                      # LTX-2 container especÃ­fico
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ model_config.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ wan21/                     # Wan 2.1 container
â”œâ”€â”€ magi1/                     # MAGI-1 container
â”œâ”€â”€ waver/                     # Waver container
â”œâ”€â”€ scripts/                   # Scripts de utilidade
â”‚   â”œâ”€â”€ download_models.sh
â”‚   â”œâ”€â”€ health_check.py
â”‚   â””â”€â”€ benchmark.py
â”œâ”€â”€ ComfyUI/                   # ComfyUI installation
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ checkpoints/       # LTX-2 checkpoint (41GB)
â”‚   â”‚   â”œâ”€â”€ clip/              # Gemma FP8 encoder (6GB) + projections (2.7GB)
â”‚   â”‚   â””â”€â”€ vae/               # Audio VAE (208MB)
â”‚   â””â”€â”€ custom_nodes/
â”‚       â”œâ”€â”€ ComfyUI-LTXVideo/  # LTX-2 custom node
â”‚       â””â”€â”€ MAGI-1/            # MAGI-1 custom node
â”œâ”€â”€ LTX-2/                     # RepositÃ³rio oficial Lightricks
â”‚   â””â”€â”€ src/ltx_pipelines/     # API Python direta
â”œâ”€â”€ comfyui-env/               # Python venv (PyTorch 2.10.0+cu130)
â”œâ”€â”€ docker-compose.yml         # OrquestraÃ§Ã£o dos 4 containers
â”œâ”€â”€ .env                       # ConfiguraÃ§Ãµes de ambiente
â”œâ”€â”€ generate_all_videos.py    # Script de teste - submete jobs para todos os modelos
â”œâ”€â”€ check_jobs_status.py      # Script de monitoramento de jobs
â”œâ”€â”€ test_ltx2_direct.py        # Teste LTX-2 via Python API
â”œâ”€â”€ test_ltx2_cpu.py           # Teste LTX-2 em CPU (fallback)
â”œâ”€â”€ generation_results.log     # Log dos testes executados
â”œâ”€â”€ CLAUDE.md                  # InstruÃ§Ãµes para Claude Code
â”œâ”€â”€ ARCHITECTURE.md            # DocumentaÃ§Ã£o da arquitetura
â”œâ”€â”€ QUICKSTART.md              # Guia rÃ¡pido de inÃ­cio
â”œâ”€â”€ PROJECT_SUMMARY.md         # Resumo do projeto
â”œâ”€â”€ CHANGELOG.md               # HistÃ³rico de mudanÃ§as
â””â”€â”€ README.md                  # Este arquivo
```

**Volumes Docker**:
```
videosdgx_models/
â”œâ”€â”€ ltx2/           # 293GB - RepositÃ³rio completo HuggingFace
â”œâ”€â”€ wan21/          # 65GB  - Modelo Wan 2.1 completo
â”œâ”€â”€ magi1/          # Em download
â””â”€â”€ waver/          # Modelo Waver 1.0

videosdgx_outputs/  # VÃ­deos gerados pelos containers
```

## ğŸ” SeguranÃ§a

- **Sem exposiÃ§Ã£o externa**: Por padrÃ£o, APIs sÃ³ acessÃ­veis via localhost
- **Volumes isolados**: Cada container tem acesso controlado
- **Sem root**: Containers rodam com usuÃ¡rio nÃ£o-privilegiado (TODO)
- **Secrets**: Use Docker secrets para credenciais HuggingFace

## ğŸ“ˆ PrÃ³ximos Passos

- [ ] Adicionar frontend web
- [ ] Implementar autenticaÃ§Ã£o JWT
- [ ] Sistema de cache de vÃ­deos
- [ ] Auto-scaling baseado em demanda
- [ ] Prometheus + Grafana para monitoramento
- [ ] CI/CD pipeline
- [ ] Fine-tuning de modelos
- [ ] Suporte a mÃºltiplas GPUs

## ğŸ“„ LicenÃ§a

Este projeto Ã© fornecido como estÃ¡, para uso no DGX Spark 2026.

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, abra uma issue primeiro para discutir mudanÃ§as maiores.

## ğŸ“ Suporte

Para problemas, abra uma issue neste repositÃ³rio.

---

**DGX Spark 2026** | 128GB Unified Memory | ~1 PFLOP FP4 Performance
